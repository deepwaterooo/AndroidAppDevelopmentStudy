#+latex_class: cn-article
#+title: Android OpenGL ES 渲染相关
#+author: deepwaterooo

* 通过SurfaceView，TextureView，GlSurfaceView显示相机预览
** SurfaceView，TextureView，GlSurfaceView的优缺点及区别
*** SurfaceView
- 继承自View,拥有View的大部分属性，但是由于holder的存在，不能设置透明度。
  - 优点：可以在一个独立的线程中进行绘制，不会影响主线程，使用双缓冲机制，播放视频时画面更流畅
  - 缺点：surface的显示不受View属性的控制，不能将其放在ViewGroup中，SurfaceView不能嵌套使用。
- SurfaceView预览相机视图不支持透明度，可以设置缩放旋转属性。如果需要做动画特效的话不推荐使用SurfaceView显示视图。可以使用TextureView或者GlSurfaceView来显示。
*** GlSurfaceView
- GlSurfaceView继承自SurfaceView类，专门用来显示OpenGL渲染的，简单理解可以显示视频，图像及3D场景这些的。
*** SurfaceTexture
- 和SurfaceView功能类似，区别是，SurfaceTexure可以不显示在界面中。
  - 使用OpenGl对图片流进行美化，添加水印，滤镜这些操作的时候我们都是通过SurfaceTexre去处理，处理完之后再通过GlSurfaceView显示。
  - 缺点，可能会导致个别帧的延迟。本身管理着BufferQueue,所以内存消耗会多一点。
*** TextureView
- 同样继承自View，必须在开启硬件加速的设备中使用（保守估计目前百分之九十的Android设备都开启了），TextureView通过setSurfaceTextureListener的回调在子线程中进行更新UI.
  - 优点：支持动画效果。
  - 缺点：在5.0之前在主线程渲染，在5.0之后在单独线程渲染。
|------------------+--------------------+------------------------|
|                  | TextureView        | SurfaceView            |
|------------------+--------------------+------------------------|
| 绘制             | 稍微延时           | 及时                   |
| 内存             | 高                 | 低                     |
| 动画             | 支持               | 不支持                 |
| 耗电             | 高                 | 低                     |
| 适用场景（推荐） | 视频播放，相机应用 | 大量画布更新(游戏绘制) |
|------------------+--------------------+------------------------|
** 如何通过SurfaceView显示Camera预览。
- 基本步骤
  - 在xml文件中设置SurfaceView 。
  - 实现SurfaceHolder.Callback的回调。
  - 打开摄像头Camera.open(0);
  - 设置摄像头相关参数；
  - 将摄像头数据设置到SurfaceView中，并开启预览。
#+BEGIN_SRC java
@Override
    public void surfaceCreated(SurfaceHolder holder) {
    try {
        mCamera = Camera.open(0); // Open the Camera in preview mode
        mCamera.setDisplayOrientation(90);
        mCamera.setPreviewDisplay(holder);
        mCamera.startPreview();
    } catch (IOException e) {
    }
}
@Override
    public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) {
    mCamera.autoFocus(new Camera.AutoFocusCallback() {
            @Override
                public void onAutoFocus(boolean success, Camera camera) {
                if (success) {
                    mParameters = mCamera.getParameters();
                    mParameters.setPictureFormat(PixelFormat.JPEG); //图片输出格式
                    // mParameters.setFlashMode(Camera.Parameters.FLASH_MODE_TORCH);//预览持续发光
                    mParameters.setFocusMode(Camera.Parameters.FOCUS_MODE_CONTINUOUS_PICTURE);//持续对焦模式
                    mCamera.setParameters(mParameters);
                    mCamera.startPreview();
                    mCamera.cancelAutoFocus();
                }
            }
        });
}
@Override
    public void surfaceDestroyed(SurfaceHolder holder) {
    if (mCamera != null) {
        mCamera.stopPreview();
        mCamera.release();
        mCamera = null;
    }
}
#+END_SRC 
** 如何通过TextureView显示Camera预览
- TextureView和SurfaceView显示Camera数据其实差不多,差别就两点：
  - SurfaceView显示需要实现SurfaceHolder.Callback的回调而TextureView通过实现 TextureView.SurfaceTextureListener接口。
  - 当Camera使用SurfaceView预览时通过setPreviewDisplay(holder)方法来设置预览视图，而使用TextureView预览时使用setPreviewTexture(mCameraTextureView.getSurfaceTexture())方法来设置。
#+BEGIN_SRC java
public class CameraTextureViewShowActivity extends AppCompatActivity implements TextureView.SurfaceTextureListener {
    @BindView(R.id.camera_texture_view)
        TextureView mCameraTextureView;
    public Camera mCamera;
    @Override
        protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_camera_surface_texture);
        ButterKnife.bind(this);
        mCameraTextureView.setSurfaceTextureListener(this);
    }
    @Override
        public void onSurfaceTextureAvailable(SurfaceTexture surface, int width, int height) {
        try {
            mCamera = Camera.open(0);
            mCamera.setDisplayOrientation(90);
            mCamera.setPreviewTexture(mCameraTextureView.getSurfaceTexture());
            mCamera.startPreview();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
    @Override
        public void onSurfaceTextureSizeChanged(SurfaceTexture surface, int width, int height) {
    }
    @Override
        public boolean onSurfaceTextureDestroyed(SurfaceTexture surface) {
        if (mCamera != null) {
            mCamera.stopPreview();
            mCamera.release();
            mCamera = null;
        }
        return false;
    }
    @Override
        public void onSurfaceTextureUpdated(SurfaceTexture surface) {
    }
    @OnClick(R.id.btn_texture_anim)
        public void onViewClicked() {
        PropertyValuesHolder valuesHolder = PropertyValuesHolder.ofFloat("translationX", 0.0f, 0.0f);
        PropertyValuesHolder valuesHolder1 = PropertyValuesHolder.ofFloat("scaleX", 1.0f, 0.3f,1.0f);
        PropertyValuesHolder valuesHolder4 = PropertyValuesHolder.ofFloat("scaleY", 1.0f, 0.3f,1.0f);
        PropertyValuesHolder valuesHolder2 = PropertyValuesHolder.ofFloat("rotationX", 0.0f, 2 * 360.0f, 0.0F);
        PropertyValuesHolder valuesHolder5 = PropertyValuesHolder.ofFloat("rotationY", 0.0f, 2 * 360.0f, 0.0F);
        PropertyValuesHolder valuesHolder3 = PropertyValuesHolder.ofFloat("alpha", 1.0f, 0.7f, 1.0F);
        ObjectAnimator objectAnimator = ObjectAnimator.ofPropertyValuesHolder(mCameraTextureView, valuesHolder, valuesHolder1, valuesHolder2, valuesHolder3,valuesHolder4,valuesHolder5);
        objectAnimator.setDuration(5000).start();
    }
}
#+END_SRC 
** 如何通过GlSurfaceView处理Camera预览。
- 如果你在学习自定义相机，而且你的相机想要实现美颜，滤镜，人脸识别AR场景 and so on。这时候你就必须要学习如何使用GlsurfaView罗。如果你没有openGl的基本配置的知识或者你之前完全没有学习过openGl的开发，再次强烈建议你看一下这篇文章 Android openGl开发详解(一)——绘制简单图形，否则，下面内容可能会引起你的严重不适。
- 基本步骤
  - 在xml中添加GlSurfaceView
  - 创建渲染器类实现GlSurfaceView.Renderer
  - 清除画布，并创建一个纹理并绑定到。
  - 创建一个用来最后显示的SurfaceTexture来显示处理后的数据。
  - 创建Opengl ES程序并添加着色器到该程序中，创建openGl程序的可执行文件，并释放shader资源。
  - 打开摄像头，并配置相关属性。设置预览视图，并开启预览。
  - 添加程序到ES环境中，并设置及启用各类句柄。
  - 在onDrawFrame中进行画布的清理及绘制最新的数据到纹理图形中。
  - 设置一个SurfaceTexture.OnFrameAvailableListener的回调来通知GlSurfaceview渲染新的帧数据。
- 建议：GlSurfaceView作用简单的理解OpenGl对相机数据进行处理完之后的显示。我们需要明白的是渲染器的渲染周期及渲染方法的调用时机。
  - onSurfaceCreated()当surface创建(第一次进入当前页面)或者重新创建(切换后台再进入)的时候调用。
  - onSurfaceChanged()当surface大小发生改变的时候会被调用。
  - onDrawFrame()绘制当前帧数据的时候被调用。
- 大多数情况下渲染顶点着色器及片段着色器的代码会编写一个glsl的文件放到assets目录下进行访问。
- 下面是另外一个操作方式：
  - vertex_texture.glsl文件
#+BEGIN_SRC java
uniform mat4 textureTransform;
attribute vec2 inputTextureCoordinate;
attribute vec4 position;            //NDK坐标点
varying   vec2 textureCoordinate; //纹理坐标点变换后输出
void main() {
    gl_Position = position;
    textureCoordinate = inputTextureCoordinate;
}
#+END_SRC 
  - fragment_texture.glsl文件：
  #+BEGIN_SRC java
// extension GL_OES_EGL_image_external : require // comment ?
precision mediump float;
uniform samplerExternalOES videoTex;
varying vec2 textureCoordinate;
void main() {
    vec4 tc = texture2D(videoTex, textureCoordinate);
    float color = tc.r * 0.3 + tc.g * 0.59 + tc.b * 0.11;//这里进行的颜色变换处理，传说中的黑白滤镜。
    gl_FragColor = vec4(color,color,color,1.0);
}
  #+END_SRC 
  - 读取文件内容方式：
  #+BEGIN_SRC java
public static String read(Context context, String fileName) {
    String result = null;
    try {
        InputStream is = context.getResources().getAssets().open("Shader/" + fileName);
        int length = is.available();
        byte[] buffer = new byte[length];
        is.read(buffer);
        result = new String(buffer, "utf-8");
    } catch (IOException e) {
        e.printStackTrace();
    }
    return result;
}
  #+END_SRC 
- 具体实现在上面代码creatProgram()下注释掉通常做法的那部分。
- GLSurfaceView上的实现：
#+BEGIN_SRC java
@Override
    public void onSurfaceCreated(GL10 gl, EGLConfig config) {
    GLES20.glClearColor(0.0f, 0.0f, 0.0f, 0.0f);
    mSurfaceTexture = new SurfaceTexture(createOESTextureObject());
    creatProgram();
    // mProgram = ShaderUtils.createProgram(CameraGlSurfaceShowActivity.this, "vertex_texture.glsl", "fragment_texture.glsl");
    camera = Camera.open(camera_status);
    try {
        camera.setPreviewTexture(mSurfaceTexture);
        camera.startPreview();
    } catch (IOException e) {
        e.printStackTrace();
    }
    activeProgram();

}
@Override
    public void onSurfaceChanged(GL10 gl, int width, int height) {
    GLES20.glViewport(0, 0, width, height);
    Matrix.scaleM(mMVPMatrix,0,1,-1,1);
    float ratio = (float) width / height;
    Matrix.orthoM(mProjectMatrix, 0, -1, 1, -ratio, ratio, 1, 7);// 3和7代表远近视点与眼睛的距离，非坐标点
    Matrix.setLookAtM(mCameraMatrix, 0, 0, 0, 3, 0f, 0f, 0f, 0f, 1.0f, 0.0f);// 3代表眼睛的坐标点
    Matrix.multiplyMM(mMVPMatrix, 0, mProjectMatrix, 0, mCameraMatrix, 0);
}
@Override
    public void onDrawFrame(GL10 gl) {
    if (mBoolean){
        activeProgram();
        mBoolean = false;
    }
    if (mSurfaceTexture != null) { // <<<<<=====
        GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT | GLES20.GL_DEPTH_BUFFER_BIT);
        mSurfaceTexture.updateTexImage();
        GLES20.glUniformMatrix4fv(mMVPMatrixHandle, 1, false, mMVPMatrix, 0);
        GLES20.glDrawArrays(GLES20.GL_TRIANGLE_STRIP, 0, mPosCoordinate.length / 2);
    }
}
#+END_SRC 
- 关于前后摄像头的切换的问题，我上面的做法是在点击切换摄像头操作的时候只针对摄像头进行了释放重启操作，直接在onDrawFrame方法中对渲染矩阵进行了修改，没有对SurfaceTexture进行数据清除（具体看上面代码）。然而也看了一些主流的第三方Demo，这里不列出名字了。他们的做法是摄像头和surfaceTexture一块释放。当然，两种方式都可以，我上面的那种方式暂时没找到什么问题，而且我通过实测比第二种方式看到相机数据的时间要快一点。
- 做相机项目，最好能将每个步骤都弄清楚，逻辑理清楚了会节省很大一部分时间
** 视频录制
- 请求相机功能
  - 如果您的应用程序的基本功能涉及到 拍照，请将其在Google Play上的可见性限制为具有相机的设备。 以声明您的应用程序依赖于摄像头，请在清单文件中放置<uses-feature>标记。
#+BEGIN_SRC xml
<manifest ... >
    <uses-feature android:name="android.hardware.camera"
                  android:required="true" />
</manifest>
#+END_SRC
- 使用相机应用录制视频
#+BEGIN_SRC java
const val REQUEST_VIDEO_CAPTURE = 1
private fun dispatchTakeVideoIntent() {
    Intent(MediaStore.ACTION_VIDEO_CAPTURE).also { takeVideoIntent ->
        takeVideoIntent.resolveActivity(packageManager)?.also {
            startActivityForResult(takeVideoIntent, REQUEST_VIDEO_CAPTURE)
        }
    }
}
#+END_SRC 
- 观看视频
#+BEGIN_SRC java
override fun onActivityResult(requestCode: Int, resultCode: Int, intent: Intent) {
    if (requestCode == REQUEST_VIDEO_CAPTURE && resultCode == RESULT_OK) {
        val videoUri: Uri = intent.data
        mVideoView.setVideoURI(videoUri)
    }
#+END_SRC 

* 渲染步骤
- 初始化 EGL 环境大概分了 6 个步骤，在代码中都标记出来了。我们一个个来看。
  - 获得 EGLDisplay 对象，官网解释说是一个 display connection。可能其内部封装了连接设备显示器，获取显示器信息的方法。
  - 初始化 1 中获得的 display connection。这一步传入了 version 数组，作用是用来存放调用 eglInitialize 方法后获取的 EGL 的主版本和次版本。因为在 c 语言中一般是通过入参来传递返回值的，所以这里也是类似。
  - 获得显示器支持的图像缓冲配置，这里主要指定了各个颜色的深度和 alpha 通道的深度。然后调用 eglChooseConfig 方法后会返回多个支持我们指定配置的配置。这些配置会按匹配程度排序，数组第一个是最接近我们需要的配置。
  - 拿到配置后就可以创建 EGLContext，它为后续 OpenGL ES 渲染提供了上下文。
  - 创建 EGLSurface，已经有了 SurfaceView 了，这里为什么又来了一个 EGLSurface？其实 EGL 并不认识 SurfaceView，他只认识 EGLSurface，所以就用 EGLSurface 对 SurfaceView 中的 Surface 做了一层代理，实际上绘制还是绘制在 SurfaceView 中的 BufferQueue 中然后给屏幕进行显示的。
  - 最后一步即将 EGL 绑定到当前的 EGLSurface 上来，并指定了 OpenGL ES 的渲染上下文。
- 经过以上这 6 步，我们已经具备使用 OpenGL ES 进行渲染的能力了，下面来看下该怎么做。

- 首先在 SurfaceHolder 的 surfaceCreated 方法中调用上面的 initEGL，然后指定 OpenGL ES 的清屏颜色。
#+BEGIN_SRC java
@Override
    public void surfaceCreated(SurfaceHolder holder) {
        initEGL(holder);
        GLES32.glClearColor(1.0F, 0F, 0F, 1F);
    }
#+END_SRC 
- 接着在 surfaceChanged 回调中设置 OpenGL ES 中的视窗大小，并进行清屏操作。但仅仅这两步是无法将清屏颜色渲染到屏幕上的，因为此时只是将颜色渲染在了 EGLSurface 中的缓存中，另外还需要调用 EGL14.eglSwapBuffers 将缓存中的数据给到显示设备，这样才能渲染成功。
#+BEGIN_SRC java
@Override
public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) {
    GLES32.glViewport(0, 0, width, height);
    GLES32.glClear(GLES32.GL_COLOR_BUFFER_BIT);
    EGL14.eglSwapBuffers(mEGLDisplay, mEGLSurface);
#+END_SRC 

** OpenGL fundamentals
- GLSurfaceView是一个视图，继承至SurfaceView，它内嵌的surface专门负责OpenGL渲染。
*** GLSurfaceView提供了下列特性：
- 1> 管理一个surface，这个surface就是一块特殊的内存，能直接排版到android的视图view上。
- 2> 管理一个EGL display，它能让opengl把内容渲染到上述的surface上。
- 3> 用户自定义渲染器(render)。
- 4> 让渲染器在独立的线程里运作，和UI线程分离。
- 5> 支持按需渲染(on-demand)和连续渲染(continuous)。
- 6> 一些可选工具，如调试。
*** 使用GLSurfaceView
- 通常会继承GLSurfaceView，并重载一些和用户输入事件有关的方法。如果你不需要重载事件方法，GLSurfaceView也可以直接使用，你可以使用set方法来为该类提供自定义的行为。例如，GLSurfaceView的渲染被委托给渲染器在独立的渲染线程里进行，这一点和普通视图不一样，setRenderer(Renderer)设置渲染器。
*** 初始化GLSurfaceView
- 初始化过程其实仅需要你使用setRenderer(Renderer)设置一个渲染器(render)。当然，你也可以修改GLSurfaceView一些默认配置。
  - * setDebugFlags(int)
  - * setEGLConfigChooser(boolean)
  - * setEGLConfigChooser(EGLConfigChooser)
  - * setEGLConfigChooser(int, int, int, int, int, int)
  - * setGLWrapper(GLWrapper) 
*** 定制android.view.Surface
- GLSurfaceView默认会创建像素格式为PixelFormat.RGB_565的surface。如果需要透明效果，调用getHolder().setFormat(PixelFormat.TRANSLUCENT)。透明(TRANSLUCENT)的surface的像素格式都是32位，每个色彩单元都是8位深度，像素格式是设备相关的，这意味着它可能是ARGB、RGBA或其它。
*** 选择EGL配置
- Android设备往往支持多种EGL配置，可以使用不同数目的通道(channel)，也可以指定每个通道具有不同数目的位(bits)深度。因此，在渲染器工作之前就应该指定EGL的配置。GLSurfaceView默认EGL配置的像素格式为RGB_656，16位的深度缓存(depth buffer)，默认不开启遮罩缓存(stencil buffer)。
- 如果你要选择不同的EGL配置，请使用setEGLConfigChooser方法中的一种。
*** 调试行为
- 你可以调用调试方法setDebugFlags(int)或setGLWrapper(GLSurfaceView.GLWrapper)来自定义GLSurfaceView一些行为。在setRenderer方法之前或之后都可以调用调试方法，不过最好是在之前调用，这样它们能立即生效。
*** 设置渲染器
- 总之，你必须调用setRenderer(GLSurfaceView.Renderer)来注册一个GLSurfaceView.Renderer渲染器。渲染器负责真正的GL渲染工作。
*** 渲染模式
- 渲染器设定之后，你可以使用setRenderMode(int)指定渲染模式是按需(on demand)还是连续(continuous)。默认是连续渲染。
*** Activity生命周期
- Activity窗口暂停(pause)或恢复(resume)时，GLSurfaceView都会收到通知，此时它的onPause方法和onResume方法应该被调用。这样做是为了让GLSurfaceView暂停或恢复它的渲染线程，以便它及时释放或重建OpenGL的资源。

** 事件处理 
- 系统默认mode==RENDERMODE_CONTINUOUSLY，这样系统会自动重绘；mode==RENDERMODE_WHEN_DIRTY时，只有surfaceCreate的时候会绘制一次，然后就需要通过requestRender()方法主动请求重绘。同时也提到，如果你的界面不需要频繁的刷新最好是设置成RENDERMODE_WHEN_DIRTY，这样可以降低CPU和GPU的活动，可以省电。
- 为了处理事件，一般都是继承GLSurfaceView类并重载它的事件方法。但是由于GLSurfaceView是多线程操作，所以需要一些特殊的处理。由于渲染器在独立的渲染线程里，你应该使用Java的跨线程机制跟渲染器通讯。queueEvent(Runnable)方法就是一种相对简单的操作。
- *这里关于多线程处理的部分，是之前自己不曾注意到过的，需要理解原理和加强*
-  (注：如果在UI线程里调用渲染器的方法，很容易收到“call to OpenGL ES API with no current context”的警告，典型的误区就是在键盘或鼠标事件方法里直接调用opengl es的API，因为UI事件和渲染绘制在不同的线程里。更甚者，这种情况下调用glDeleteBuffers这种释放资源的方法，可能引起程序的崩溃，因为UI线程想释放它，渲染线程却要使用它。)
#+BEGIN_SRC java
class MyGLSurfaceView extends GLSurfaceView { 
     private MyRenderer mMyRenderer; 
         public void start() { 
             mMyRenderer = ...; 
             setRenderer(mMyRenderer); 
         } 
         public boolean onKeyDown( int keyCode, KeyEvent event) { 
             if (keyCode == KeyEvent.KEYCODE_DPAD_CENTER) { 
                 queueEvent( new Runnable() { 
                     // 这个方法会在渲染线程里被调用 
                          public void run() { 
                              mMyRenderer.handleDpadCenter(); 
                          }}); 
                      return true ; 
                  } 
                  return super .onKeyDown(keyCode, event); 
             } 
       } 
}
#+END_SRC 
- 调用queueEvent就是给队列中添加runnable
#+BEGIN_SRC java
public void queueEvent(Runnable r) {
     synchronized (sGLThreadManager) {
         mEventQueue.add(r);
         sGLThreadManager.notifyAll();
     }
}
#+END_SRC 
- 在guardenRun()中有如下代码：
#+BEGIN_SRC java
 if (! mEventQueue.isEmpty()) {
     event = mEventQueue.remove( 0 );
     break ;
 }
 if (event != null ) {
     event.run();
     event = null ;
     continue ;
 }
#+END_SRC 
- 因为每次都会remove掉添加的runnable，所以上面那个demo就是非常好的解释，每次按键就是添加runnable。当然，这也是要求绘制是一直在循环重绘的状态才能看到效果。
- (注：如果在UI线程里调用渲染器的方法，很容易收到“call to OpenGL ES API with no current context”的警告，典型的误区就是在键盘或鼠标事件方法里直接调用opengl es的API，因为UI事件和渲染绘制在不同的线程里。更甚者，这种情况下调用glDeleteBuffers这种释放资源的方法，可能引起程序的崩溃，因为UI线程想释放它，渲染线程却要使用它。)
- 再举一下简单实用的小例子，关于queueEvent()的使用的
#+BEGIN_SRC java
public class ClearActivity extends Activity {
    private GLSurfaceView mGLView;
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        // mGLView = new GLSurfaceView(this);
        mGLView = new ClearGLSurfaceView(this);
        mGLView.setRenderer(new ClearRenderer());
        setContentView(mGLView);
    }
     @Override
    protected void onPause() {
        super.onPause();
        mGLView.onPause();
    }
     @Override
     protected void onResume() {
        super.onResume();
        mGLView.onResume();
    }
}
class ClearGLSurfaceView extends GLSurfaceView {
    public ClearGLSurfaceView(Context context) {
        super(context);
        mRenderer = new ClearRenderer();
        setRenderer(mRenderer);
    }
    public boolean onTouchEvent(final MotionEvent event) {
        queueEvent(new Runnable(){
            public void run() {
                mRenderer.setColor(event.getX() / getWidth(),
                        event.getY() / getHeight(), 1.0f);
            }});
            return true;
        }
        ClearRenderer mRenderer;
}
class ClearRenderer implements GLSurfaceView.Renderer {
    private float mRed;
    private float mGreen;
    private float mBlue;
    public void onSurfaceCreated(GL10 gl, EGLConfig config) {
        // Do nothing special.
    }
    public void onSurfaceChanged(GL10 gl, int w, int h) {
        gl.glViewport(0, 0, w, h);
    }
    public void onDrawFrame(GL10 gl) {
        gl.glClearColor(mRed, mGreen, mBlue, 1.0f);
        gl.glClear(GL10.GL_COLOR_BUFFER_BIT | GL10.GL_DEPTH_BUFFER_BIT);
    }
    public void setColor(float r, float g, float b) {
        mRed = r;
        mGreen = g;
        mBlue = b;
    }
}
#+END_SRC 
- 这个应用每帧都在清楚屏幕。当你点击屏幕时，它清除颜色基于你触屏时间的X、Y坐标。注意在 ClearGLSurfaceView.onTouchEvent()中使用queueEvent()。queueEvent()方法被安全地用于在UI线程和渲染线程之间进行交流。如果你愿意，你还可以使用一些其他的java线程间交流技术，例如Renderer 类本身的同步方法。然而，queueing 事件经常是一种用于处理线程间信息交流的更简单方式。


* 顶点属性、顶点数组和缓冲区对象
** 顶点属性和顶点数组
- 顶点数组中包含了每一个顶点的属性，是保存在用户内核的缓冲区。(语文不好的跟我念：顶点数组是缓冲区，这个缓冲区在用户内核，里面存放的是每一个顶点的属性)。
*** 单个顶点属性
- 如果我们有单个的顶点需要处理的话，可以使用下列方法将一个顶点对象映射为一个索引，这样我们就可以在需要的地方使用索引而不是顶点对象去操作数据。OpenGL提供了下列方法去创建单个顶点对象。
#+BEGIN_SRC cpp
  void glVertexAttrib1f (GLuint index, GLfloat x);
  void glVertexAttrib1fv (GLuint index, const GLfloat *v);
  void glVertexAttrib2f (GLuint index, GLfloat x, GLfloat y);
  void glVertexAttrib2fv (GLuint index, const GLfloat *v);
  void glVertexAttrib3f (GLuint index, GLfloat x, GLfloat y, GLfloat z);
  void glVertexAttrib3fv (GLuint index, const GLfloat *v);
  void glVertexAttrib4f (GLuint index, GLfloat x, GLfloat y, GLfloat z, GLfloat w);
  void glVertexAttrib4fv (GLuint index, const GLfloat *v);
#+END_SRC 
*** 顶点数组
    #+BEGIN_SRC cpp
void glVertexAttribPointer (GLuint index, GLint size, GLenum type, GLboolean normalized, GLsizei stride, const void *pointer);
void glVertexAttribIPointer (GLuint index, GLint size, GLenum type, GLsizei stride, const void *pointer);
    #+END_SRC 
- 前一个方法允许任何数字类型数组，后一个方法只允许整型数组。
  - index：顶点索引，可由用户自行指定。
  - size：对于坐标来说不应该使用size(尺度)最贴切的是dimension(维度)，取值范围1~4，代表当前顶点使用的坐标系，是线性坐标系(只有x)，或是4维空间坐标系(x,y,z,w)。
  - type：数据格式，包括常用的数据类型，比如GL_FLOAT等。
  - normalized：是否规范化，对于使用glVertexAttribPointer方法的非GL_FLOAT数组，将次标记设置为真后，有符号数将被按比例映射到GL_FLOAT[-1.0，1.0]区间，无符号数将被按比例映射到[0，1.0]区间。
  - stride：偏移量，如果该数组不仅仅用于存放坐标的话，需要说明偏移量，否则设置为0即可。
  - ptr：用作缓冲区的数组
*** 启用和关闭顶点数组
- 如果我们使用index指定了一个顶点数组，那么我们可以使用以下两种方式选择开启或者关闭使用此顶点数组。
  - void glEnableVertexAttribArray (GLuint index);
  - void glDisableVertexAttribArray (GLuint index);
*** 布局限定符
- 一旦我们将一个索引与顶点数组绑定起来，我们就可以在着色器中自由的使用数组中的数据。这种方式使用起来最为方便，但是在某些情况下，我们可能还需要另外的方式(值得注意的是，这种绑定在下一次程序链接时生效)
  - void glBindAttribLocation (GLuint program, GLuint index, const GLchar *name);
  - program：程序对象索引。
  - index：定点数组索引。
  - name：着色器中使用此数据的变量的名称。
- 例如：我们可以使用此方法修改7.4.1中的着色器
  - glBindAttribLocation(program,0,"pos");//用户程序添加绑定
  - in vec2 pos;//不需要布局限定符
** 顶点数组对象
- 使用顶点数组操作可能需要多次调用8.1中的方法来切换状态。实际上在OpenGL ES 3.0 中，同一时刻总是只有一个活动的顶点数组对象。那么我们可以通过更简单的方法去指定当前正在使用的顶点数组。使用方式就是记录一段你需要对该数组进行的操作，并保存到一个操作对象当中，然后再每次需要时调用此操作记录对象即可。
*** 创建顶点数组对象
    #+BEGIN_SRC cpp
void glGenVertexArrays (GLsizei n, GLuint *arrays);
    #+END_SRC 
- n：需要的顶点数组对象个数
- arrays：保存对象索引的数组
*** 绑定顶点数组对象
- 顶点数组对象的目的是简化操作，我们需要将一个数组对象和一系列关于顶点数组和缓存的操作绑定起来。当我们调用完毕下列方法的时候，其后所有关于顶点数组和缓存的操作都将被记录到顶点数组对象的状态当中。
#+BEGIN_SRC cpp
void glBindVertexArray (GLuint array);
#+END_SRC 
- array：需要使用或修改状态的顶点数组对象的索引。
*** 删除顶点数组对象
- 同理，当我们不再需要对一段顶点数组进行操作的时候，需要通知OpenGL删除关于此数组的操作记录。我们可以使用如下方法：
#+BEGIN_SRC cpp
void glDeleteVertexArrays (GLsizei n, const GLuint *arrays);
#+END_SRC 
- n：需要删除的对象个数。
- arrays：包含数组对象索引的数组。
** 顶点缓冲区对象
- 假如我们将数据存储到用户内存，那么每当我们调用绘图方法时，都需要将数据从用户内存复制到图形内存中。但是我们没有必要再每次绘图时都去复制数据。为了节省内存和电力开销，OpenGL ES 提供了顶点缓存技术。OpenGL ES 3.0支持两类缓存区对象：
  - GL_ARRAY_BUFFER：标志指定缓冲区用于保存顶点数据
  - GL_ELEMENT_ARRAY_BUFFER：标志指定缓冲区用于保存图元索引数据
*** 获取缓冲区索引
- 由于这个缓冲区需要在两个内核空间中共享，所以OpenGL不建议像创建顶点数组那样让用户自己去指定索引。OpenGL提供了一个函数用来获取当前空闲的缓冲区索引。
#+BEGIN_SRC cpp
void glGenBuffers (GLsizei n, GLuint *buffers);
#+END_SRC 
- n：需要得到的索引数量。
- buffers：保存索引的数组。
*** 绑定缓冲区
- 我们通过8.3.1获取到了可用的缓冲区索引，接下来我们需要将索引与缓冲区类型进行绑定。
#+BEGIN_SRC cpp
void glBindBuffer (GLenum target, GLuint buffer);
#+END_SRC 
- target：缓冲区存放的数据类型。
- buffer：已获取的缓冲区索引。
*** 绑定数据
- 如果我们通过8.3.2绑定了缓冲区索引，接下来就可以将数据绑定到缓冲区了。
#+BEGIN_SRC cpp
void glBufferData (GLenum target, GLsizeiptr size, const void *data, GLenum usage);
#+END_SRC 
- target：缓冲区存放的数据结构。
- size：缓冲区大小，单位：字节。
- data：数据源，其内容将会被复制到缓冲区中。
- usage：缓冲区的使用方法。
- 使用方式主要分为以下三类：
- 只读型(一次修改多次访问)：
  - GL_STATIC_DRAW
  - GL_STATIC_READ
  - GL_STATIC_COPY
- 读写型(多次修改多次访问)：
  - GL_DYNAMIC_DRAW
  - GL_DYNAMIC_READ
  - GL_DYNAMIC_COPY
- 数据流型(一次修改一次访问)：
  - GL_STREAM_DREW
  - GL_STREAM_READ
  - GL_STREAM_COPY
- 这三种类型的后缀DRAW表示数据将被送往GPU渲染、READ表述数据会回传给用户程序、COPY表示其同时具有前两种性质。
- 该方法中的data可以为NULL，如果传入NULL则表示延迟初始化。那么我们应该使用什么方法去再次加载数据呢？接下来介绍一个可以初始化和更新数据的函数：
#+BEGIN_SRC cpp
void glBufferSubData (GLenum target, GLintptr offset, GLsizeiptr size, const void *data);
#+END_SRC 
- offset：缓冲区待修改数据偏移量。
- size：被修改的数据存储字节数。
- data：数据源。
*** 删除缓冲区
- 当我们使用完缓冲区后，应当命令OpenGL销毁这个区域：
#+BEGIN_SRC cpp
void glDeleteBuffers (GLsizei n, const GLuint *buffers);
#+END_SRC 
- n：要删除的缓冲区个数。
- buffers：包含缓冲区索引的数组。
** 映射缓冲区对象
- 当我们需要操作保存在缓冲区的数据时会发现，仅通过8.4节的方式是不能高效的满足需求的。因为我们需要在程序中保存一个引用并不断的调用glBufferSubData方法去更新缓冲区，此时缓冲区的存在完全没有意义。为了你补这个缺陷，OpenGL ES 3.0 中提供了映射缓冲区对象的概念，通过映射缓冲区对象，我们可以直接获得缓冲区中的数据引用——在某些共享内存的架构上，映射缓冲区甚至可以直接得到GPU存储缓冲区地址的直接指针——从而提高性能。
*** 获取缓冲区对象指针
- 我们可以通过以下指令获取指向所有或部分缓存的指针，如果出现错误，该函数将返回NULL。
#+BEGIN_SRC cpp
void* glMapBufferRange (GLenum target, GLintptr offset, GLsizeiptr length, GLbitfield access);
#+END_SRC 
  - target：缓冲区存放的数据结构。
  - offset：缓冲区数据存储的偏移量，单位：字节。
  - length：需要的缓冲区字节数。
  - access：访问方式，是如下方式的一种或组合。
- 缓冲区对象的访问方式：
- 必须包含的选项：
  - GL_MAP_READ_BIT：只读
  - GL_MAP_WRITE_BIT：读写
- 可选的选项：
  - GL_MAP_INVALIDATE_RANGE：告诉OpenGL之前该范围内的数据可能被丢弃。这个标志不得与GL_MAP_READ_BIT结合使用。
  - GL_MAP_INVALIDATE_BUFFER_BIT：告诉OpenGL之前所有的数据都可能被丢弃。这个标志不得与GL_MAP_READ_BIT结合使用。
  - GL_MAP_FLUSH_EXPLICIT_BIT：这个标志只能与GL_MAP_WRITE_BIT一起使用。当使用了此标志之后，需要应用程序明确的使用glFlushMappedBufferRange函数刷新操作。在没有使用此标识位的情况下，glUnmapBuffer函数被调用时会自动刷新。
  - GL_MAP_UNSYNCHRONIZED_BIT：告诉OpenGL不要同步等待glMapBufferRange之前的操作，也就是说指定了该标识之后，会立即从缓冲区中获取引用，无论前面是否还有其他对缓冲区的操作。
*** 取消缓冲区映射
- 当我们不再使用缓冲区映射时，需要使用如下函数解除当前正在使用的映射关系
  - GLboolean glUnmapBuffer (GLenum target);
  - target：缓冲区存放的数据结构。
*** 刷新缓冲区
- 如果我们希望对映射的修改能够立即同步到缓冲区，可以使用glUnmapBuffer解除映射，然后映射中的数据就会被自动刷新到缓冲区中。但是这种方式缺点明显，比如对于连续刷新来说操作繁琐，而且，假如只修改一小部分数据，这种方式却刷新了整个缓冲区。OpenGL ES 3.0提供了部分刷新的方法
#+BEGIN_SRC cpp
void glFlushMappedBufferRange (GLenum target, GLintptr offset, GLsizeiptr length);
#+END_SRC 
- target：缓冲区存放的数据结构。
- offset：缓冲区数据存储的偏移量，单位：字节。
- length：从偏移点开始刷新的长度。
*** 复制缓冲区对象
- OpenGL提供了如下所示的函数来在两个缓冲区之间复制数据
#+BEGIN_SRC cpp
void glCopyBufferSubData (GLenum readTarget, GLenum writeTarget, GLintptr readOffset, GLintptr writeOffset, GLsizeiptr size);
#+END_SRC 
- readTarget：源缓冲区存放的数据结构。
- writeTarget：目标缓冲区存放的数据结构。
- readOffset：源缓冲区偏移量。
- writeOffset：目标缓冲区偏移量。
- size：需要复制的字节长度。